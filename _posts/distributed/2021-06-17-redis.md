---
layout: post
title: Redis总结
category: springcloud
tags: [springcloud]
---

## 参考资料
[java架构直通车-第7周 主从复制高可用Redis集群](https://class.imooc.com/sale/javaarchitect)  
[java架构直通车-第8周 Redis缓存雪崩，穿透](https://class.imooc.com/sale/javaarchitect)

## 一.分布式架构概述 + Redis入门与基础
### 1-1 分布式架构概述 
系统架构尽量不要过度设计，最好随着业务发展扩大来演进  
- 单体架构：
    - 优点：
        - 小团队、迭代周期短、速度快、部署运维简单
    - 缺点：
        - 单节点宕机即服务不可用（解决方案：多节点、集群）
        - 系统复杂后耦合度高（解决方案：服务拆分解耦、微服务）
        - 单节点并发能力有限（解决方案：负载均衡分摊压力）
- 集群架构：多节点组成，每个节点服务相同
    - 优点：
        - 高可靠：提高单体应用的并发能力
        - 高可用：单节点宕机仍可用
        - 可扩展性：增减节点
    - 缺点：
        - 分布式会话
        - 定时任务、mq延时任务实现定时任务
        - 部署复杂
- 分布式架构：不同业务子系统部署在不同服务器上；
    - 每个子系统可负责一个或多个业务
    - 子系统（服务）间可通信
    - 子系统可集群部署
    - 对用户透明
    - 优点：
        - 业务解耦
        - 系统模块化，可复用化
        - 提高系统并发：因为业务请求被分散到不同服务器上 
    - 缺点：
        - 架构复杂度增加
        - 调试复杂
        - 部署复杂
        - 子系统通信耗时、异常状况
        - 新人融入慢
    - 设计原则
        - 异步解耦，mq
        - 幂等一致性
        - 拆分原则
        - 融合分布式中间件
        - 容错、高可用

### 1-4 什么是分布式缓存，什么是Redis？ 为何引入Redis？ Redis使用场景？
1）分布式缓存：再分布式架构中（分布式服务器节点）使用的缓存技术，最著名的分布式缓存例子莫过于Memcached、 Redis
- 能有效地降低对后台服务器的压力
- 高性能的读取速度
- 进行分布式计算
- 跨服务器缓存
- 内存式缓存

2）[Redis](http://www.redis.cn/)：Redis是一种Key-Value键值型的内存数据库

**3）为何引入Redis**  
二八原则：80%是读操作  
![](https://wdsheng0i.github.io/assets/images/2021/redis/yinru.png)

**4）Redis适用场景**  
[Redis应用场景](https://blog.csdn.net/hguisu/article/details/8836819)    
[Redis常见应用场景](https://www.jianshu.com/p/40dbc78711c8)    
[Redis-使用场景](https://blog.csdn.net/sinat_27143551/article/details/80599170)    
- 缓存(数据查询、短连接、新闻内容、商品内容等等)。(最多使用) 代替memcached, 最新列表&排行榜，这里采用Redis的List数据结构或sorted set结构,方便实现最新列表or排行榜 等业务场景。
    - 商品列表
    - 收藏列表
    - 好友列表
    - 评论列表
    - @提示列表
- 分布式集群架构中的session分离。 
- 任务队列。(秒杀、抢购、12306等等) 
- 消息队列
- 应用排行榜。 
- 网站访问统计。 
- 数据过期处理(可以精确到毫秒)：**登录验证码，短信验证码**
- 聊天室的在线好友列表。 
- 存储社交关系  
譬如将用戶的好友/粉丝/关注，可以存在一个sortedset中，score可以是timestamp，这样求两个人的共同好友的操作，可能就只需要用求交集命令即可 
- 各种计数，商品维度计数和用户维度计数  
Redis的命令都是原子性的，你可以轻松地利用INCR，DECR等命令来计数。  
商品维度计数（喜欢数，评论数，鉴定数，浏览数,etc）  
用户维度计数（动态数、关注数、粉丝数、喜欢商品数、发帖数 等）

### 1-5 分布式缓存方案与技术选型对比：Redis VS Memcache VS Ehcache 
https://www.cnblogs.com/qlqwjy/p/7788912.html  
**Redis**  
Redis是一个开源的使用ANSIC语言编写、支持网络、可基于内存亦可持久化的日志型、高性能的Key-Value数据库
- 优点  
    - 内存数据库：性能极高 – Redis能支持超过 100K+ 每秒的读写频率。
    - 单进程单线程，线程安全
    - 采用 IO 多路复用机制，非阻塞IO(epoll)
    - 丰富的数据类型 – Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。
    - 可持久化
    - 支持分布式、集群、主从同步等
    - 丰富的特性 – Redis还支持 publish/subscribe, 通知, key 过期等等特性。
    - 原子 – Redis的所有操作都是原子性的，同时Redis还支持对几个操作全并后的原子性执行。
    - 发布订阅

- 缺点
    - 数据库容量受到物理内存的限制
    - 单进程单线
    
**Ehcache**  
是一个纯Java的进程内缓存框架,具有快速、精干等特点,是Hibernate中默认CacheProvider。

- 特性：  
    - 1.快速、简单：基于JVM      
    - 2.多种缓存策略      
    - 3.缓存数据有两级：内存和磁盘，因此无需担心容量问题      
    - 4.缓存数据会在虚拟机重启的过程中写入磁盘      
    - 5.可以通过RMI、可插入API等方式进行分布式缓存      
    - 6.具有缓存和缓存管理器的侦听接口  
    - 7.支持多缓存管理器实例，以及一个实例的多个缓存区域      
    - 8.提供Hibernate的缓存实现 

- 缺点：      
    - 集群、分布式架构下 不支持

**Memcached**    
基于一个存储键/值对的hashmap。其守护进程（daemon）是用C写的，但是客户端可以用任何语言来编写，并通过memcached协议与守护进程通信  
- 特点：   
    - 内存数据库：性能极高 
    - 简单的key-value存储  
    - 内存使用率高  
    - 数据类型简单  
    - 多核处理，多线程  

- 缺点：  
    - 无法持久化，无法容灾  
    - 数据类型单一：String

### 1-6-7 安装与配置Redis 
1 Linux环境[安装](https://blog.csdn.net/yuanlong122716/article/details/104347670)  
```
1.下载：
访问 https://redis.io/download  到官网进行下载  
或者 wget https://download.redis.io/releases/redis-3.x.x.tar.gz

2.解压
##/opt/redis为举例的安装目录.
mkdir /opt/redis
tar ‐zxvf redis‐3.x.x.tar.gz ‐C /opt/redis

3.编译
# 安装依赖
yum install gcc-c++
#切入目录
cd /opt/redis/redis‐3.x.x 
#编译
make 
#安装
make install
// 备注：// make test you need tcl8.5 or newer   需要安装tcl
下载tcl8.6.0: 
进入unix, 
执行./configure,
生成Makefile, 
执行make
执行make install
安装tcl后, make test 报错, 修改tests/integration/replication-psync.tcl文件,修改after后的100->500

4.移动可执行文件至bin目录
mkdir /opt/redis/redis‐3.x.x/bin
回车
mv redis‐trib.rb redis‐server redis‐sentinel redis‐cli redis‐check‐dump redis‐check‐aof redis‐
benchmark mkreleasehdr.sh /opt/redis/redis‐3.x.x/bin
回车

5.移动配置文件到bin目录
mkdir /opt/redis/redis‐3.x.x/bin
mv /opt/redis/redis‐3.x.x/redis.conf /opt/redis/redis‐3.x.x/bin

6.修改配置文件
vim /opt/redis/redis‐3.x.x/bin/redis.conf
/requirepass  #搜索密码, 释放注释, 修改密码
bind 127.0.0.1   #注释掉
daemonize yes  #守护进程：前台运行、后台运行
dir ./  修改为 dir/usr/local/reids/work  #持久化目录

7.启动服务
cd /opt/redis/redis‐3.x.x/bin
./redis‐server redis.conf

8.测试启动是否成功：如果运行以下命令后出现：Could not connect to Redis at xxxx: Connection refused.则说明启动不成功；如果进入了redis交互页面，则说明启动成功了。
cd /opt/redis/redis‐3.x.x/bin
./redis‐cli ‐p %port端口号% ‐a %requirepass设置的密码%  //redis-cli -h 127.0.0.1 -p 6379 -a 123456

9.设置开机自启动
进入redis/utils目录
复制文件：cp redis_int_script /ect/int.d/
执行 vim redis_int_script 添加
#chkconfig: 22345 10 90
#description: Start and Stop redis
执行 chkconfig redis_int_script on 注册
```

2 windows环境[安装](https://blog.csdn.net/antma/article/details/79225084)  
Redis项目不正式支持Windows。但是，微软开发并维护了针对Win64的Windows版本。    
下载地址：https://github.com/tporadowski/redis/releases。    
Windows版本下载地址：https://github.com/MicrosoftArchive/redis/releases    
安装：https://www.cnblogs.com/skmobi/p/11696620.html    
```
1.下载

2.解压

3.启动：打开cmd命令进入redis目录，
执行  E:\redis>redis-server.exe redis.windows.conf

4.链接：启动后窗口不要关，新开一个cmd窗口
执行 E:\redis>redis-cli ==>默认连接本机127.0.0.1 端口号 6379，连接成功。

5、将Redis 加入 Windows 服务，执行
redis-server --service-install redis.windows.conf
提示：Redis successfully installed as a service.表示加入服务成功！
如果 Redis 设置了密码，加入服务时会提示: Granting read/write access to 'NT AUTHORITY\NetworkService' on: "E:\redis" "E:\redis\"

可以服务列表redis的属性里加启动参数：-a 123456
```
3 reids配置详解
```
==基本配置
daemonize no 是否以后台进程启动
databases 16 创建database的数量(默认选中的是database 0)

save 900 1    #刷新快照到硬盘中，必须满足两者要求才会触发，即900秒之后至少1个关键字发生变化。
save 300 10  #必须是300秒之后至少10个关键字发生变化。
save 60 10000 #必须是60秒之后至少10000个关键字发生变化。
stop-writes-on-bgsave-error yes    #后台存储错误停止写。
rdbcompression yes    #使用LZF压缩rdb文件。
rdbchecksum yes    #存储和加载rdb文件时校验。
dbfilename dump.rdb    #设置rdb文件名。
dir ./    #设置工作目录，rdb文件会写入该目录。

==主从配置
slaveof <masterip> <masterport> 设为某台机器的从服务器
masterauth <master-password>   连接主服务器的密码
slave-serve-stale-data yes  # 当主从断开或正在复制中,从服务器是否应答
slave-read-only yes #从服务器只读
repl-ping-slave-period 10 #从ping主的时间间隔,秒为单位
repl-timeout 60 #主从超时时间(超时认为断线了),要比period大
slave-priority 100    #如果master不能再正常工作，那么会在多个slave中，选择优先值最小的一个slave提升为master，优先值为0表示不能提升为master。

repl-disable-tcp-nodelay no #主端是否合并数据,大块发送给slave
slave-priority 100 从服务器的优先级,当主服挂了,会自动挑slave priority最小的为主服

===安全
requirepass foobared # 需要密码
rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52 #如果公共环境,可以重命名部分敏感命令 如config

===限制
maxclients 10000 #最大连接数
maxmemory <bytes> #最大使用内存

maxmemory-policy volatile-lru #内存到极限后的处理
volatile-lru -> LRU算法删除过期key
allkeys-lru -> LRU算法删除key(不区分过不过期)
volatile-random -> 随机删除过期key
allkeys-random -> 随机删除key(不区分过不过期)
volatile-ttl -> 删除快过期的key
noeviction -> 不删除,返回错误信息

#解释 LRU ttl都是近似算法,可以选N个,再比较最适宜T踢出的数据
maxmemory-samples 3

====日志模式
appendonly no #是否仅要日志
appendfsync no # 系统缓冲,统一写,速度快
appendfsync always # 系统不缓冲,直接写,慢,丢失数据少
appendfsync everysec #折衷,每秒写1次

no-appendfsync-on-rewrite no #为yes,则其他线程的数据放内存里,合并写入(速度快,容易丢失的多)
auto-AOF-rewrite-percentage 100 当前aof文件是上次重写是大N%时重写
auto-AOF-rewrite-min-size 64mb aof重写至少要达到的大小

====慢查询
slowlog-log-slower-than 10000 #记录响应时间大于10000微秒的慢查询
slowlog-max-len 128   # 最多记录128条

```

### 1-8-9 Redis命令行客户端redis-cli基本使用 
- redis-cli -a password shutdown ：关闭redis
- ./redis_init_script stop ：关闭redis
- redis-cli ：进入到redis客户端
- auth pwd ：输入密码
- set key value ：设置缓存
- get key ：获得缓存
- del key ：删除缓存
- redis-cli -a password ping ：查看是否存活
- SETNX：是「SET if Not eXists」的缩写，就是只有key不存在时才设置值，可以防止覆盖数据
用途：用来实现分布式锁
- keys *：查看所有的key (不建议在生产上使用，有性能影响)
- type key：key的类型

### 1-10-11 Redis的数据类型 - string 
String(最大512M)：Value 不仅是 String，也可以是数字

- set key value [ex 秒数] [px 毫秒数] [nx/xx]
 　　如果ex和px同时写，则以后面的有效期为准  
 　　nx：如果key不存在则建立  
 　　xx：如果key存在则修改其值
- setnx rekey data：设置已经存在的key，不会覆盖
- get/set/del：查询/设置/删除
- mset key1 value1 key2 value2 一次设置多个值
- mget key1 key2 ：一次获取多个值
- msetnx：连续设置，如果存在则不设置
- append key value ：把value追加到key 的原值上
- setrange key offset value：把字符串的offset偏移字节改成value  如果偏移量 > 字符串长度，该字符自动补0x00
- getrange key start end：截取数据，end=-1 代表到最后
- setrange key start newdata：从start位置开始替换数据
- getrange key start stop：获取字符串中[start,stop]范围的值，下标，左数从0开始，右数从-1开始  
　　注意：当start>length，则返回空字符串，当stop>=length，则截取至字符串尾，如果start所处位置在stop右边，则返回空字符串
- getset key nrevalue：获取并返回旧值，在设置新值
- incr key：自增1，返回新值，如果incr一个不是int的value则返回错误，incr一个不存在的key，则设置key为1
- decr key：类减1
- incrby key 2：跳2自增
- incrbyfloat by 0.7： 自增浮点数
- decrby key num：累减给定数值
- setbit key offset value：设置offset对应二进制上的值，返回该位上的旧值  
　　注意：如果offset过大，则会在中间填充0 , offset最大到多少：　2^32-1，即可推出最大的字符串为512M
- bitop operation destkey key1 [key2..]对key1、key2做opecation并将结果保存在destkey上  
　　opecation可以是AND OR NOT XOR  
- strlen key：取指定key的value值的长度
- setex key time value：设置key对应的值value，并设置有效期为time秒

### 1-12-13 Redis的数据类型 - hash 
Hash：Hash 是一个 String 的 Key 和 Value 的映射表，Hash 特别适合存储对象。常用命令：hget，hset，hgetall 等  

hash：类似map，存储结构化数据结构，比如存储一个对象（不能有嵌套对象）  

Redis hash 是一个string类型的field和value的映射表，它的添加、删除操作都是O(1)（平均）。hash特别适用于存储对象，将一个对象存储在hash类型中会占用更少的内存，并且可以方便的存取整个对象。  

配置： hash_max_zipmap_entries 64 #配置字段最多64个  
　　　hash_max_zipmap_value 512 #配置value最大为512字节
- hset user field value：设置myhash的field为value,例如  "hset user name imooc"-> 创建一个user对象，这个对象中包含name属性，name值为imooc
- hsetnx key field value：不存在的情况下设置myhash的field为value
- hmset key field1 value1 field2 value2：同时设置多个field-> hset user age 18 phone 139123123
- hget key field：获取指定的hash field
- hmget key field1 field2：一次获取多个field
- hincrby key age 2：累加属性
- hincrbyfloat key age 2.2：累加属性
- hexists key age：判断属性是否存在
- hlen key：返回hash的field数量
- hdel key field：删除指定的field
- hkeys key：返回hash所有的field
- hvals key：返回hash所有的value
- hdel key：删除对象
- hgetall key：获取某个hash中全部的field及value：hgetall user：获得整个对象user的内容

### 1-14-15 Redis的数据类型 - list 
List ：双向链表实现，常用命令：lpush、rpush、lpop、rpop、lrange（获取列表片段）等  
  
Redis的list类型其实就是一个每个子元素都是string类型的双向链表，链表的最大长度是2^32。  

list既可以用做栈，也可以用做队列。   
 
list的pop操作还有阻塞版本，主要是为了避免轮询    
- lpush key value：把值插入到链表头部: lpush userList 1 2 3 4 5：构建一个list，从左边开始存入数据
- rpush key value：把值插入到链表尾部: rpush userList 1 2 3 4 5：构建一个list，从右边开始存入数据
- lpop key ：返回并删除链表头部元素,从左侧开始拿出一个数据
- rpop key： 返回并删除链表尾部元素,从右侧开始拿出一个数据
- lrange key start stop：返回链表中[start, stop]中的元素
- lrem key count value：从链表中删除value值，删除count的绝对值个value后结束，count > 0 从表头删除　　count < 0 从表尾删除　　count=0 全部删除
- lset list index value：把某个下标的值替换
- lrem list num value：删除几个相同数据
- ltrim key start stop：剪切key对应的链接，切[start, stop]一段并把改制重新赋给key
- lindex list index：获取list下标的值
- llen key：计算链表的元素个数
- llen list：list长度
- linsert key after|before searchValue value：在key 链表中寻找search，并在searchValue值之前|之后插入value
- rpoplpush source dest：把source 的末尾拿出，放到dest头部，并返回单元值
  应用场景： task + bak 双链表完成安全队列  
　业务逻辑： rpoplpush task bak接收返回值并做业务处理，如果成功则rpop bak清除任务，如果不成功，下次从bak表取任务
- brpop，blpop key timeout：等待弹出key的尾/头元素  timeout为等待超时时间，如果timeout为0则一直等待下去，应用场景：长轮询ajax，在线聊天时能用到

### 1-16 Redis的数据类型 - set 
Set ：String 类型的无序、去重集合。集合是通过 hashtable 实现的。常用命令：sdd、spop、smembers、sunion

特点：无序性、确定性、唯一性
- （1）sadd key value1 value2：往集合里面添加元素
- （2）smembers key：获取集合所有的元素
- （3）srem key value：删除集合某个元素
- （4）spop key：返回并删除集合中1个随机元素（可以坐抽奖，不会重复抽到某人）
- （5）srandmember key：随机取一个元素
- （6）sismember key value：判断集合是否有某个值
- （7）scard key：返回集合元素的个数
- （8）smove source dest value：把source的value移动到dest集合中
- （9）sinter key1 key2 key3：求key1 key2 key3的交集
- （10）sunion key1 key2：求key1 key2 的并集
- （11）sdiff key1 key2：求key1 key2的差集
- （12）sinterstore res key1 key2：求key1 key2的交集并存在res里

### 1-17-18 Redis的数据类型 - zset 
Zset ：有序的并且不重复的集合，常用命令：zadd、zrange、zrem、zcard 等。  

概念：它是在set的基础上增加了一个顺序属性，这一属性在添加修改元素的时候可以指定，每次指定后，zset会自动按新的值调整顺序。可以理解为有两列的mysql表，一列存储value，一列存储顺序，操作中key理解为zset的名字。  

和set一样sorted，sets也是string类型元素的集合，不同的是每个元素都会关联一个double型的score。sorted set的实现是skip list和hash table的混合体。  

当元素被添加到集合中时，一个元素到score的映射被添加到hash table中，所以给定一个元素获取score的开销是O(1)。另一个score到元素的映射被添加的skip list，并按照score排序，所以就可以有序地获取集合中的元素。添加、删除操作开销都是O(logN)和skip list的开销一致，redis的skip list 实现是双向链表，这样就可以逆序从尾部去元素。sorted set最经常使用方式应该就是作为索引来使用，我们可以把要排序的字段作为score存储，对象的ID当元素存储。  
- （1）zadd key score1 value1 score2 value2：添加元素
- （2）zrange key start stop [withscores]：把集合排序后,返回名次[start,stop]的元素  默认是升续排列  withscores 是把score也打印出来
- （3）zrank key member：查询member的排名（升序0名开始）
- （4）zrangebyscore key min max [withscores] limit offset N：集合（升序）排序后取score在[min, max]内的元素，并跳过offset个，取出N个
- （5）zrevrank key member：查询member排名（降序 0名开始）
- （6）zremrangebyscore key min max：按照score来删除元素，删除score在[min, max]之间
- （7）zrem key value1 value2：删除集合中的元素
- （8）zremrangebyrank key start end：按排名删除元素，删除名次在[start, end]之间的
- （9）zcard key：返回集合元素的个数
- （10）zcount key min max：返回[min, max]区间内元素数量
- （11）zinterstore dest numkeys key1[key2..] [WEIGHTS weight1 [weight2...]] [AGGREGATE 

## 二.SpringBoot整合Redis实战
- Jedis：是 Redis 官方首选的 Java 客户端开发包  
- Redisson：  
- spring-boot-starter-data-redis：集成使用RedisTemplate，spring封装Jedis操作   
- 可视化工具 redis-desktop-manager

### 2-1 聊一聊多路复用器，阻塞和非阻塞 

### 2-2 Redis 架构单线程模型原理解析 
![](https://wdsheng0i.github.io/assets/images/2021/redis/redis-thread.png)

单线程为什么快：IO多路复用 + 内存操作 + 单线程避免上下文切换损耗

### 2-3 SpringBoot整合Redis实战 
```
//1.添加依赖
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-data-redis</artifactId>
</dependency>

//2.配置Redis，没有设置序列化器RedisTemplate会选择默认序列化器JdkSerializationRedisSerializer
//SpringBoot会自动在容器中生成一个RedisTemplate和一个StringRedisTemplate
//但是这个RedisTemplate的泛型是<Object,Object>，在代码中的需要类型转换，使用不方便、安全，
//并且RedisTemplate没有设置序列化方式，对象的状态信息转为存储或传输的形式需要序列化。
//所以我们需要自己配置RedisConfig：
@Configuration
public class RedisConfig {
    @Bean
    public RedisTemplate<String, Object> redisTemplate(RedisConnectionFactory factory) {
        RedisTemplate<String, Object> template = new RedisTemplate<String, Object>();
        template.setConnectionFactory(factory);
        // 使用Jackson2JsonRedisSerialize 替换默认序列化
        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);
        // 如果序列化对象中有日期格式，可以自定义日期的序列化类，处理日期的序列化方式。其他需要序列化的类型，也可以按此处理。
        ObjectMapper om = new ObjectMapper();
        // 在序列化中增加类信息，否则无法反序列化。
        om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);
        om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);
        jackson2JsonRedisSerializer.setObjectMapper(om);
        StringRedisSerializer stringRedisSerializer = new StringRedisSerializer();
        //key采用String的序列化方式
        template.setKeySerializer(stringRedisSerializer);
        //value序列化方式采用jackson
        template.setValueSerializer(jackson2JsonRedisSerializer);
        //hash的key也采用String的序列化方式
        template.setHashKeySerializer(stringRedisSerializer);
        //hash的value序列化方式采用jackson
        template.setHashValueSerializer(jackson2JsonRedisSerializer);
        template.afterPropertiesSet();
        return template;
    }
}

//3.添加配置
spring: 
  cache:
    type: redis
  redis:
    host: 127.0.0.1
    password: 123456
    # 连接超时时间（毫秒）
    timeout: 10000
    # Redis默认情况下有16个分片，这里配置具体使用的分片，默认是0
    database: 0
    lettuce:
      pool:
        # 连接池最大连接数（使用负值表示没有限制） 默认 8
        max-active: 8
        # 连接池最大阻塞等待时间（使用负值表示没有限制） 默认 -1
        max-wait: -1
        # 连接池中的最大空闲连接 默认 8
        max-idle: 8
        # 连接池中的最小空闲连接 默认 0
        min-idle: 0

//4.封装redis服务类RedisService或者直接使用redisTemplate
@Autowired 
private RedisTemplate redisTemplate; 
redisTemplate.opsForValue().set(key, value);

//使用RedisService
redisService.setTakeOverTime("key1", "123", 10L);
``` 

## 三.Redis进阶提升与主从复制   

### 3-1 Redis 的发布（pub）与订阅（sub） 
虽然有发布订阅功能，但是不建议用作消息，专做缓存更专业  
![](https://wdsheng0i.github.io/assets/images/2021/redis/pub-sub.png)

```
//订阅:执行命令后开始监听chanel
# redic-cli
>subscribe food java bigdata
Reading messages...(press Ctrl-C to quit)

//发布：
# redic-cli
>public food duck

//监听结果: 订阅者收到发布的信息
"message" "food" "duck"

//批量订阅：所有imooc开头的chanel
# redic-cli
>psubscribe imooc*
Reading messages...(press Ctrl-C to quit)
```

### 3-2-3 Redis的持久化机制 - RDB(redis-database)  
RDB(redis-database): 每隔特定时间, 内存快照备份-dump.rdb，恢复的时候把快照文件读进内存  

优势：
- 全量备份、灾备恢复快、效率高、
- 子进程备份时，主进程不会有写入修改或删除，保证备份数据的完整性 
 
劣势：
- 非实时存在丢少量数据风险、
- 子进程占用内存会和父进程一样，造成CPU负担

RDB的配置 
```
1.保存位置，可以在redis.conf自定义：
dir /usr/local/redis/working
dbfilename dump.rdb  

2.保存机制：
save 900 1 
save 300 10 
save 60 10000 
save 10 3 
* 如果1个缓存更新，则15分钟后备份 
* 如果10个缓存更新，则5分钟后备份 
* 如果10000个缓存更新，则1分钟后备份 
* 演示：更新3个缓存，10秒后备份 
* 演示：备份dump.rdb，删除重启 
1.stop-writes-on-bgsave-error
    yes：如果save过程出错，则停止写操作
    no：可能造成数据不一致
2.rdbcompression
    yes：开启rdb压缩模式
    no：关闭，会节约cpu损耗，但是文件会大，道理同nginx
3.rdbchecksum
```

### 3-4-5 Redis的持久化机制 - AOF(append-only-file)
- 1.以日志的形式来记录用户请求的写操作。读操作不会记录，写操作才会存存储。  
- 2.文件以追加的形式而不是修改的形式。  
- 3.redis的aof恢复其实就是把追加的文件从开始到结尾读取执行写操作。  

优势
- 1.实时持久化，可以秒级别为单位备份，如发生问题，也只会丢失最后一秒的数据，增加了可靠性和数据完整性   
- 2.以log日志形式追加，如磁盘满了，会执行redis-check-aof工具
- 3.数据太大时，redis可以后台自动重写aof。当redis继续把日志追加到老的文件中去时，重写是非常安全的，不会影响客户端作。
- 4.AOF日志包含所有写操作，便于redis的解析恢复。

劣势
- 1.相同的数据，同一份数据，AOF比RDB大，恢复效率低
- 2.针对不同的同步机制，AOF会比RDB慢，因为AOF每秒都会备份做写操作，这样相对与RDB来说就略低。 每秒备份fsync没毛病，但是
的每次写入就做一次备份fsync的话，那么redis的性能就会下降。

AOF配置
```
# AOF 默认关闭，yes可以开启 
appendonly no 

# AOF 的文件名 
appendfilename "appendonly.aof" 

# no：不同步 
# everysec：每秒备份，推荐使用 
# always：每次操作都会备份，安全并且数据完整，但是慢性能差 
appendfsync everysec 

# 重写的时候是否要同步，no可以保证数据安全 
no-appendfsync-on-rewrite no 

# 重写机制：避免文件越来越大，自动优化压缩指令，会fork一个新的进程去完成重写动作，新进程里的内存数据会被重写 
# 当前AOF文件的大小是上次AOF大小的100% 并且文件体积达到64m，满足两者则触发重写 
auto-aof-rewrite-percentage 100 
auto-aof-rewrite-min-size 64mb
```
**到底采用RDB还是AOF呢？**   
1.如果你能接受一段时间的缓存丢失，那么可以使用RDB  
2.如果你对实时性的数据比较care，那么就用AOF  
    

### Redis4.0-AOF/RDB混合持久化模式

### 3-6 Redis 主从复制原理解析 

### 3-7 多虚拟机克隆方案 

### 3-8 搭建Redis主从复制Master-slave（读写分离） 

### 3-9 Redis无磁盘化复制原理解析 

### 3-10-11 Redis 缓存过期处理与内存淘汰机制 
内存淘汰[回收机制](https://blog.csdn.net/yuanlong122716/article/details/104420880)
- 设置超期: 最近最少使用、即将超期、随机
- 未设置超期: 最近最少使用、随机
- 不淘汰

过期[删除策略](https://blog.csdn.net/yuanlong122716/article/details/104420880)
- 定期删除：每过段时间检查一次redis，删除里面过期键
- 惰性删除：每次取时检查是否过期需要删除
- 定时删除：设置超期时设置定时器

## 四.Redis 哨兵机制与实现
- 监控、提醒、自动故障转移  
- Redis哨兵架构及数据丢失问题分析

### 4-1 Redis 的哨兵模式 

### 4-2 Redis 哨兵机制与实现 - 1  

### 4-3 Redis 哨兵机制与实现 - 2 

### 4-4 解决原Master恢复后不同步问题 

### 4-5 图解哨兵 

### 4-6 附：哨兵信息检查 

### 4-7-8 SpringBoot 集成Redis哨兵 -配置 

### 4-9 redis实现分布式锁
[Redis实现分布式锁](https://blog.csdn.net/yuanlong122716/article/details/104366372)  
[Redis分布式锁的Java实现（基于Lua脚本）](https://blog.csdn.net/yuanlong122716/article/details/104366469)

## 五.Redis集群
- 3.0-redis-cluster: Redis Custer数据分布式算法-Hash slot
- twemproxy
- codis

### 5-1-2 Redis-Cluster 集群 与环境准备 
``` 
### 配置内核参数
echo "vm.overcommit_memory=1" >> /etc/sysctl.conf
sysctl -p

### 编译安装
redis集群搭建
home_dir=/data/redis

### 所有节点操作
1、安装相关依赖
$ yum install -y gcc gcc-c++

2、下载解压
cd /data/packages
wget https://download.redis.io/releases/redis-5.0.12.tar.gz
tar -zxf redis-5.0.12.tar.gz

cd redis-5.0.12
make
make PREFIX=/data/redis install

### 分别在各节点机器操作
1、创建redis 集群节点
mkdir -p /data/logs/redis
cd /data/redis
mkdir -p cluster/{7000,7001,7002}---节点1
mkdir -p cluster/{7003,7004,7005}---节点2

2、修改配置
port 7000                                          //端口7000,7002,7003       
bind 0.0.0.0                                        //默认ip为127.0.0.1 需要改为其他节点机器可访问的ip 否则创建集群时无法访问对应的端口，无法创建集群
daemonize yes                                       //redis后台运行
pidfile /var/run/redis_7000.pid                     //pidfile文件对应7000,7001,7002
dbfilename 7000.rdb                                 //rdb文件对应7000,7001,7002
dir /data/redis/cluster/7000/                       //修改集群节点对应文件夹7000,7001,7002
cluster-enabled yes                                 //开启集群  把注释#去掉
cluster-config-file nodes_7000.conf                 //集群的配置  配置文件首次启动自动生成 7000,7001,7002
cluster-node-timeout 15000                          //请求超时  默认15秒，可自行设置
appendonly yes                                      //aof日志开启  有需要就开启，它会每次写操作都记录一条日
logfile "/data/logs/redis/redis_7000.log"               //日志存放路径

3、启动所有节点
/data/redis/bin/redis-server /data/redis/cluster/7000/redis.conf
/data/redis/bin/redis-server /data/redis/cluster/7001/redis.conf
/data/redis/bin/redis-server /data/redis/cluster/7002/redis.conf
 
/data/redis/bin/redis-server /data/redis/cluster/7003/redis.conf
/data/redis/bin/redis-server /data/redis/cluster/7004/redis.conf
/data/redis/bin/redis-server /data/redis/cluster/7005/redis.conf

### 创建集群
/data/redis/bin/redis-cli --cluster create IP1:7000 IP1:7001 IP1:7002 IP2:7003 IP2:7004 IP2:7005 --cluster-replicas 1

出现Can I set the above configuration?(type ‘yes’ to accept):输入yes,等待集群创建完成
```

### 5-3-4 搭建Redis的三主三从集群模式 

### 5-5 什么是slot槽节点 

### 5-6 Springboot集成Redis集群

## 六.Redis缓存雪崩、击穿、穿透、一致性等常见问题与批量查询的优化设计 
- 缓存[雪崩、击穿、穿透、一致性等常见问题](https://blog.csdn.net/yuanlong122716/article/details/104383926)

### 6-1 缓存穿透的解决方案 

### 6-2 缓存穿透之布隆过滤器 

### 6-3 布隆过滤器基本思想 

### 6-4 使用布隆过滤器 

### 6-5 缓存雪崩与预防 
**1).缓存雪崩**：缓存全失效、过期、缓存服务器故障->请求全查库  
解决方案：  
- 缓存reload机制、提前更新缓存、设置过期时间尽量随机分散  
- 主从或集群，提供备用缓存服务  
- 后台限流降级、加锁或队列控制读写
**2).缓存穿透**：查一个不存在的数据，缓存中无，库中无，所以不会更新到缓存中，每次都会查库    
解决方案：[布隆过滤器](https://blog.csdn.net/yuanlong122716/article/details/104402602)，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉

**3).缓存击穿**：数据存在，但在redis中已过期，此时大量并发请求都会从DB加载数据并回设到缓存    
解决方案：使用互斥锁(mutex key)，在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法

**4).缓存一致性问题**: 先写库再更缓存、或者先更缓存再写库，都可能出现异常导致数据不一致问题

### 6-6 multiGet 批量查询优化 

### 6-7 pipeline 批量查询优化  

### 6-10 可能会遇到的面试题

### 如何保证Redis缓存和数据库的[双写一致性](https://blog.csdn.net/yuanlong122716/article/details/104444315)


-- ----------------------------------------

## 七.附：redis[命令](http://redisdoc.com/)
### key pattern 查询相应的key
- （1）redis允许模糊查询key　　有3个通配符  *、?、[]
- （2）randomkey：返回随机key
- （3）type key：返回key存储的类型
- （4）exists key：判断某个key是否存在  
	举例：exists 00c11b4e-7cc8-496b-b5b4-27134a8f08a0  
	返回1 存在 返回0不存在
- （5）del key：删除key
- （6）rename key newkey：改名
- （7）renamenx key newkey：如果newkey不存在则修改成功
- （8）move key 1：将key移动到1数据库
- （9）ttl key：查询key的生命周期（秒）:time to live
- （10）expire key 整数值：设置key的生命周期以秒为单位
- （11）pexpire key 整数值：设置key的生命周期以毫秒为单位
- （12）pttl key：查询key 的生命周期（毫秒）
- （13）perisist key：把指定key设置为永久有效

### 服务器相关命令
禁用：flushall 清空整个 Redis 服务器的数据(删除所有数据库的所有 key )
- select index：切换数据库，总共默认16个
- （1）ping：测定连接是否存活
- （2）echo：在命令行打印一些内容
- （3）select：选择数据库
- （4）quit：退出连接
- （5）dbsize：返回当前数据库中key的数目
- （6）info：获取服务器的信息和统计
- （7）monitor：实时转储收到的请求
- （8）config get 配置项：获取服务器配置的信息  
　　config set 配置项  值：设置配置项信息
- （9）flushdb：删除当前选择数据库中所有的key
- （10）flushall：删除所有数据库中的所有的key
- （11）time：显示服务器时间，时间戳（秒），微秒数
- （12）bgrewriteaof：后台保存rdb快照
- （13）bgsave：后台保存rdb快照
- （14）save：保存rdb快照
- （15）lastsave：上次保存时间
- （16）shutdown [save/nosave]  
注意：如果不小心运行了flushall，立即shutdown nosave，关闭服务器，然后手工编辑aof文件，去掉文件中的flushall相关行，然后开启服务器，就可以倒回原来是数据。如果flushall之后，系统恰好bgwriteaof了，那么aof就清空了，数据丢失。  
- （17）showlog：显示慢查询    


```
====服务端命令
time  返回时间戳+微秒
dbsize 返回key的数量
bgrewriteaof 重写aof
bgsave 后台开启子进程dump数据
save 阻塞进程dump数据
lastsave 

slaveof host port 做host port的从服务器(数据清空,复制新主内容)
slaveof no one 变成主服务器(原数据不丢失,一般用于主服失败后)

flushdb  清空当前数据库的所有数据
flushall 清空所有数据库的所有数据(误用了怎么办?)

shutdown [save/nosave] 关闭服务器,保存数据,修改AOF(如果设置)

slowlog get 获取慢查询日志
slowlog len 获取慢查询日志条数
slowlog reset 清空慢查询

info []

config get 选项(支持*通配)
config set 选项 值
config rewrite 把值写到配置文件
config restart 更新info命令的信息

debug object key #调试选项,看一个key的情况
debug segfault #模拟段错误,让服务器崩溃
object key (refcount|encoding|idletime)
monitor #打开控制台,观察命令(调试用)
client list #列出所有连接
client kill #杀死某个连接  CLIENT KILL 127.0.0.1:43501
client getname #获取连接的名称 默认nil
client setname "名称" #设置连接名称,便于调试

====连接命令===
auth 密码 #密码登陆(如果有密码)
ping #测试服务器是否可用
echo "some content" #测试服务器是否正常交互
select 0/1/2...#选择数据库
quit #退出连接 
```   

### 常见问题汇总
问：多慢才叫慢？    
答：由slowlog-log-slower-than 10000，来指定（单位为微秒）    

问：服务器存储多少条慢查询记录    
答：由slowlog-max-len 128，来做限制

如果不小心运行了flushall, 立即 shutdown nosave ,关闭服务器
然后 手工编辑aof文件, 去掉文件中的 “flushall ”相关行, 然后开启服务器,就可以导入回原来数据.

 












