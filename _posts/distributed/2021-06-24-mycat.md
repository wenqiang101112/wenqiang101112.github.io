---
layout: post
title: 分布式数据库-mycat分库分表
category: springcloud
tags: [springcloud]
---

分布式数据库：mycat分库分表 读写分离

## 参考资料 

## Mycat安装及分库分表的简单使用
需要提前准备两个数据库以便于测试，这里的两台Linux虚拟机已经装了Mysql服务。以下的安装和配置都是在Linux系统下进行的。

| IP | 端口 | 用户名 | 密码 |
| :--- | :--- | :--- | :--- |
| 192.168.232.54 | 3306 | root | 123456 |
| 192.168.232.153 | 3306 | root | 123456 |
 

## 一、安装
MyCAT 是使用 JAVA 语言进行编写开发，使用前需要先安装 JAVA 运行环境(JRE),由于 MyCAT 中使用了JDK7 中的一些特性，所以要求必须在 JDK7 以上的版本上运行。先简单介绍一下jdk1.8的安装。

### 1.1  安装JDK
JDK1.8的rpm安装包链接：[https://pan.baidu.com/s/152NmMY7h9d1YO9G12mIUvA](https://pan.baidu.com/s/152NmMY7h9d1YO9G12mIUvA) 提取码：zu33 

下载完jdk-8u281-linux-x64.rpm，拷贝进linux系统的目录。  
![image.png](https://cdn.nlark.com/yuque/0/2021/png/12493186/1611819910496-4641a53f-0c92-44ba-b419-f0931a1fb9cd.png#align=left&display=inline&height=161&margin=%5Bobject%20Object%5D&name=image.png&originHeight=214&originWidth=865&size=15024&status=done&style=none&width=651)

进入目录，使用rpm -ivh  jdk-8u281-linux-x64.rpm命令安装jdk。等待安装成功，输入java -version查看确认安装完毕。  
![image.png](https://cdn.nlark.com/yuque/0/2021/png/12493186/1611820055932-7c6ca395-9c9e-4edb-a7ae-4ecdeff822e5.png#align=left&display=inline&height=353&margin=%5Bobject%20Object%5D&name=image.png&originHeight=353&originWidth=645&size=32465&status=done&style=none&width=645)

### 1.2  安装Mycat
Mycat1.6安装包链接：[https://pan.baidu.com/s/164QQTW9zNkv1V5yUVCGgNQ](https://pan.baidu.com/s/164QQTW9zNkv1V5yUVCGgNQ)提取码：bi6p 。

下载后上传到Linux上，解压安装包命令 tar -xvf Mycat-server-1.6.7.1-release-20190627191042-linux.tar。
安装完之后，mycat目录下的内容如下:

- bin:命令文件
- catlet:空的,扩展
- conf:配置文件(server.xml,schema.xml,rule.xml等)
- lib:依赖的jar包
- logs:启动日志和运行日志文件

![image.png](https://cdn.nlark.com/yuque/0/2021/png/12493186/1611820489336-5928aec4-742f-47a4-8b25-4dfafe41fba2.png#align=left&display=inline&height=157&margin=%5Bobject%20Object%5D&name=image.png&originHeight=157&originWidth=497&size=14605&status=done&style=none&width=497)

## 二、配置
这里需要简单配置3个mycat的配置文件，都在conf目录下，包括schema.xml、server.xml和rule.xml三个文件。

### 2.1  schema.xml
MYCAT_HOME/conf/schema.xml 中定义逻辑库，表、分片节点、MySQL库等内容。本文使用配置内容如下:
``` 
<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE mycat:schema SYSTEM "schema.dtd">
<mycat:schema xmlns:mycat="http://io.mycat/">
    <!-- name：为mycat逻辑库的名字，对应server<property name="schemas">mydatabase</property>，
    建议设置跟数据库一样的名称
    checkSQLschema：自动检查逻辑库名称并拼接，true会在sql语句中的表名前拼接逻辑库名，
    例如select * from mydatabase.t_user;
    sqlMaxLimit：查询保护、如果没有写limit条件，会自动拼接。只查询100条。
    -->
    <schema name="mydatabase" checkSQLschema="true" sqlMaxLimit="100">
        <!-- name:为物理数据库的表名，命名与物理数据库的一致
        dataNode:为dataNode标签(<dataNode name="dn1" dataHost="dtHost1" database="db1" />)里面的name值
        dataNode里面填写的节点数量必须和rule里面的规则数量一致
        例如rule里面只定义了两个0-1M=0  1M-2M=1那么此处只可以指定两个节点,1M=10000，M为单位万
        primaryKey:为表的ID字段，建议和rule.xml里面指定的ID和物理库的ID一致
        rule：分片规则，对应rule.xml中<tableRule name="student_id">的name
        type：表格类型，默认非global，用于全局表定义
        -->
        <table name="t_user" dataNode="dn1,dn2,dn3" primaryKey="id" rule="auto-sharding-long">
            <!--ER分片注意childTable 标签需要放到table标签内，是主外键关联关系，
                name:为物理数据库的表名，命名与物理数据库的一致
                primaryKey:为表t_loginlog的ID字段，建议和rule.xml里面指定的ID和物理库的ID一致.
                joinKey：从表t_loginlog的外键字段，需要和物理库的字段名称一致
                parentKey：为主表t_user的字段名，依据此字段做关联，进行ER分片-->
            <childTable name="t_loginlog" primaryKey="id" joinKey="user_id" parentKey="id"></childTable>
        </table>
        <table name="t_student" dataNode="dn1,dn3" primaryKey="id" rule="student_id" />
        <table name="t_dictionaries" dataNode="dn1,dn2,dn3" type="global" />
        <table name="t_teacher" dataNode="dn1" />
    </schema>

    <!-- name：节点名称，用于在table标签里面调用
    dataHost:dataHost标签name值(<dataHost name="dtHost1">)
    database:物理数据库名，需要提前创建好实际存在的-->
    <dataNode name="dn1" dataHost="dtHost1" database="db1" />
    <dataNode name="dn2" dataHost="dtHost1" database="db2" />
    <dataNode name="dn3" dataHost="dtHost2" database="db3" />

    <!--name：节点名称，在上方dataNode标签中调用
    maxCon:底层数据库的链接最大数
    minCon:底层数据库的链接最小数
    balance:值可以为0,1,2,3,分别表示对当前datahost中维护的数据库们的读操作逻辑
    0:不开启读写分离，所有的读写操作都在最小的索引号的writeHost(第一个writeHost标签)
    1：全部的readHost和备用writeHost都参与读数据的平衡，如果读的请求过多，负责写的第一个writeHost也分担一部分
    2 ：所有的读操作，都随机的在所有的writeHost和readHost中进行
    3 ：所有的读操作，都到writeHost对应的readHost上进行（备用writeHost不参加了）,在集群中没有配置ReadHost的情况下,读都到第
    一个writeHost完成
    writeType:控制当前datahost维护的数据库集群的写操作
    0：所有的写操作都在第一个writeHost标签的数据库进行
    1：所有的写操作，都随机分配到所有的writeHost（mycat1.5完全不建议配置了）
    dbtype：数据库类型（不同数据库配置不同名称，mysql）
    dbDriver:数据库驱动，native,动态获取
    switchType：切换的逻辑
    -1：故障不切换
    1：故障切换，当前写操作的writeHost故障，进行切换，切换到下一个writeHost；
    slaveThreshold：标签中的<heartbeat>用来检测后端数据库的心跳sql语句;本属性检查从节点与主节点的同步情况(延迟时间数),配合心
    跳语句show slave status; 读写分离时,所有的readHost的数据都可靠-->
  
    <dataHost name="dtHost1" maxCon="1000" minCon="10" balance="1"
              writeType="0" dbType="mysql" dbDriver="native" switchType="1"  slaveThreshold="100">
        <!--用于验证心跳，这个是mysql主库的配置-->
        <heartbeat>select user()</heartbeat>

        <writeHost host="127.0.0.1" url="192.168.244.105:3306" user="root" password="123456">
            <readHost host="127.0.0.1" url="192.168.244.105:3306" user="root" password="123456" />
        </writeHost>

    </dataHost>
  
    <dataHost name="dtHost2" maxCon="1000" minCon="10" balance="1"
              writeType="0" dbType="mysql" dbDriver="native" switchType="1"  slaveThreshold="100">
        <!--用于验证心跳，这个是mysql主库的配置-->
        <heartbeat>select user()</heartbeat>

        <writeHost host="127.0.0.1" url="192.168.244.106:3306" user="root" password="123456">
            <readHost host="127.0.0.1" url="192.168.244.106:3306" user="root" password="123456" />
        </writeHost>

    </dataHost>
</mycat:schema>

```
 文件中的注释详细解释了标签和属性的含义，现在简单概括一下。

-  <schema>标签配置的是逻辑库的信息，即能在Mycat 8066端口能看到的库，并不一定是物理库上的数据库。
- <dataNode>标签配置的是数据库节点的信息。
- <dataHost>数据库主机的配置，这里的配置就是提前准备的两个数据库服务。

### 2.2  server.xml
MYCAT_HOME/conf/server.xml 中定义用户以及系统相关变量，如端口等。本文使用配置内容如下:
``` 
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE mycat:server SYSTEM "server.dtd">
<mycat:server xmlns:mycat="http://io.mycat/">
    <system>
        <!--配置的端口号-->
        <property name="serverPort">8066</property>
        <property name="nonePasswordLogin">0</property> <!-- 0为需要密码登陆、1为不需要密码登陆 ,默认为0，设置为1则需要指定默认账户-->
        <property name="useHandshakeV10">1</property>
        <property name="useSqlStat">0</property>  <!-- 1为开启实时统计、0为关闭 -->
        <property name="useGlobleTableCheck">0</property>  <!-- 1为开启全加班一致性检测、0为关闭 -->
        <property name="sequnceHandlerType">2</property>
        <property name="subqueryRelationshipCheck">false</property> <!-- 子查询中存在关联查询的情况下,检查关联字段中是否有分片字段 .默认 false -->
        <!--  <property name="useCompression">1</property>--> <!--1为开启mysql压缩协议-->
        <!--  <property name="fakeMySQLVersion">5.6.20</property>--> <!--设置模拟的MySQL版本号-->
        <!-- <property name="processorBufferChunk">40960</property> -->
        <!--<property name="processors">1</property>
        <property name="processorExecutor">32</property>-->
        <!--默认为type 0: DirectByteBufferPool | type 1 ByteBufferArena | type 2 NettyBufferPool -->
        <property name="processorBufferPoolType">0</property>
        <!--默认是65535 64K 用于sql解析时最大文本长度 -->
        <!--<property name="maxStringLiteralLength">65535</property>-->
        <!--<property name="sequnceHandlerType">0</property>-->
        <!--<property name="backSocketNoDelay">1</property>-->
        <!--<property name="frontSocketNoDelay">1</property>-->
        <!--<property name="processorExecutor">16</property>-->
        <!--<property name="serverPort">8066</property> <property name="managerPort">9066</property>
            <property name="idleTimeout">300000</property> <property name="bindIp">0.0.0.0</property>
            <property name="frontWriteQueueSize">4096</property> <property name="processors">32</property> -->
        <!--分布式事务开关，0为不过滤分布式事务，1为过滤分布式事务（如果分布式事务内只涉及全局表，则不过滤），2为不过滤分布式事务,但是记录分布式事务日志-->
        <property name="handleDistributedTransactions">0</property>
        <!-- off heap for merge/order/group/limit      1开启   0关闭-->
        <property name="useOffHeapForMerge">1</property>
        <!--单位为m-->
        <property name="memoryPageSize">64k</property>
        <!--单位为k-->
        <property name="spillsFileBufferSize">1k</property>
        <property name="useStreamOutput">0</property>
        <!--单位为m -->
        <property name="systemReserveMemorySize">384m</property>
        <!--是否采用zookeeper协调切换  -->
        <property name="useZKSwitch">false</property>
        <!-- XA Recovery Log日志路径 -->
        <!--<property name="XARecoveryLogBaseDir">./</property>-->
        <!-- XA Recovery Log日志名称 -->
        <!--<property name="XARecoveryLogBaseName">tmlog</property>-->
        <!--如果为 true的话 严格遵守隔离级别,不会在仅仅只有select语句的时候在事务中切换连接-->
        <property name="strictTxIsolation">false</property>
        <property name="useZKSwitch">true</property>
    </system>
    <!-- 全局SQL防火墙设置 -->
    <!--白名单可以使用通配符%或着*-->
    <!--例如<host host="127.0.0.*" user="root"/>-->
    <!--例如<host host="127.0.*" user="root"/>-->
    <!--例如<host host="127.*" user="root"/>-->
    <!--例如<host host="1*7.*" user="root"/>-->
    <!--这些配置情况下对于127.0.0.1都能以root账户登录-->
    <!-- 此处是开放了本机和外网的请求链接，因为我的mycat安装在虚拟机上，所以本机是通过ip链接
    192.*是为了让navicat可以连接使用(配置完整的虚拟机IP也可以)
    127.*是为了让虚拟机本身可以通过命令连接-->
    <firewall>
        <whitehost>
            <host host="192.*" user="root"/>
            <host host="127.*" user="root"/>
        </whitehost>
        <blacklist check="false">
        </blacklist>
    </firewall>
    <!-- 此处定义了一个root用户，可以管理的逻辑库为mydatabase，对应schema.xml中的<schema name="mydatabase" > -->
    <user name="root" defaultAccount="true">
        <property name="password">123456</property>
        <property name="schemas">mydatabase</property>
        <!-- 表级 DML 权限设置 -->
        <!--
        <privileges check="false">
            <schema name="TESTDB" dml="0110" >
                <table name="tb01" dml="0000"></table>
                <table name="tb02" dml="1111"></table>
            </schema>
        </privileges>
         -->
    </user>
    <!--<user name="user">
        <property name="password">123456</property>
        <property name="schemas">mycat1,test3</property>
        <property name="readOnly">true</property>
    </user>-->
</mycat:server>
```
server.xml文件中<system>标签下的serverPort属性，配置了mycat服务端的连接端口，工具和项目都用这个端口进行连接，这里配置的是8066端口。<user>标签定义了连接用户的信息。

### 2.3  rule.xml
MYCAT_HOME/conf/rule.xml 中定义分片规则。本文使用配置内容如下:
``` 
<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE mycat:rule SYSTEM "rule.dtd">
<mycat:rule xmlns:mycat="http://io.mycat/">
    <!--schema.xml中配置的rule="student_id" 所对应的规则，规则对应主键，
    列名为id需要与数据库的列名对应algorithm对应下方function-->
    <tableRule name="student_id">
        <rule>
            <columns>id</columns>
            <algorithm>student_text</algorithm>
        </rule>
    </tableRule>
    <tableRule name="rule1">
        <rule>
            <columns>id</columns>
            <algorithm>func1</algorithm>
        </rule>
    </tableRule>

    <tableRule name="rule2">
        <rule>
            <columns>user_id</columns>
            <algorithm>func1</algorithm>
        </rule>
    </tableRule>

    <tableRule name="sharding-by-intfile">
        <rule>
            <columns>sharding_id</columns>
            <algorithm>hash-int</algorithm>
        </rule>
    </tableRule>
    <tableRule name="auto-sharding-long">
        <rule>
            <columns>id</columns>
            <algorithm>rang-long</algorithm>
        </rule>
    </tableRule>
    <tableRule name="mod-long">
        <rule>
            <columns>id</columns>
            <algorithm>mod-long</algorithm>
        </rule>
    </tableRule>
    <tableRule name="sharding-by-murmur">
        <rule>
            <columns>id</columns>
            <algorithm>murmur</algorithm>
        </rule>
    </tableRule>
    <tableRule name="crc32slot">
        <rule>
            <columns>id</columns>
            <algorithm>crc32slot</algorithm>
        </rule>
    </tableRule>
    <tableRule name="sharding-by-month">
        <rule>
            <columns>create_time</columns>
            <algorithm>partbymonth</algorithm>
        </rule>
    </tableRule>
    <tableRule name="latest-month-calldate">
        <rule>
            <columns>calldate</columns>
            <algorithm>latestMonth</algorithm>
        </rule>
    </tableRule>
    <tableRule name="auto-sharding-rang-mod">
        <rule>
            <columns>id</columns>
            <algorithm>rang-mod</algorithm>
        </rule>
    </tableRule>
    <tableRule name="jch">
        <rule>
            <columns>id</columns>
            <algorithm>jump-consistent-hash</algorithm>
        </rule>
    </tableRule>
    <!--在conf中需要添加student_text.txt规则文件-->
    <function name="student_text"
              class="io.mycat.route.function.AutoPartitionByLong">
        <property name="mapFile">student_text.txt</property>
    </function>
    <function name="murmur"
              class="io.mycat.route.function.PartitionByMurmurHash">
        <property name="seed">0</property><!-- 默认是0 -->
        <property name="count">2</property><!-- 要分片的数据库节点数量，必须指定，否则没法分片 -->
        <property name="virtualBucketTimes">160</property><!-- 一个实际的数据库节点被映射为这么多虚拟节点，默认是160倍，也就是虚拟节点数是物理节点数的160倍 -->
        <!-- <property name="weightMapFile">weightMapFile</property> 节点的权重，没有指定权重的节点默认是1。以properties文件的格式填写，以从0开始到count-1的整数值也就是节点索引为key，以节点权重值为值。所有权重值必须是正整数，否则以1代替 -->
        <!-- <property name="bucketMapPath">/etc/mycat/bucketMapPath</property>
            用于测试时观察各物理节点与虚拟节点的分布情况，如果指定了这个属性，会把虚拟节点的murmur hash值与物理节点的映射按行输出到这个文件，没有默认值，如果不指定，就不会输出任何东西 -->
    </function>
    <function name="crc32slot"
              class="io.mycat.route.function.PartitionByCRC32PreSlot">
    </function>
    <function name="hash-int"
              class="io.mycat.route.function.PartitionByFileMap">
        <property name="mapFile">partition-hash-int.txt</property>
    </function>
    <function name="rang-long"
              class="io.mycat.route.function.AutoPartitionByLong">
        <property name="mapFile">autopartition-long.txt</property>
    </function>
    <function name="mod-long" class="io.mycat.route.function.PartitionByMod">
        <!-- how many data nodes -->
        <property name="count">3</property>
    </function>
    <function name="func1" class="io.mycat.route.function.PartitionByLong">
        <property name="partitionCount">8</property>
        <property name="partitionLength">128</property>
    </function>
    <function name="latestMonth"
              class="io.mycat.route.function.LatestMonthPartion">
        <property name="splitOneDay">24</property>
    </function>
    <function name="partbymonth"
              class="io.mycat.route.function.PartitionByMonth">
        <property name="dateFormat">yyyy-MM-dd</property>
        <property name="sBeginDate">2015-01-01</property>
    </function>

    <function name="rang-mod" class="io.mycat.route.function.PartitionByRangeMod">
        <property name="mapFile">partition-range-mod.txt</property>
    </function>

    <function name="jump-consistent-hash" class="io.mycat.route.function.PartitionByJumpConsistentHash">
        <property name="totalBuckets">3</property>
    </function>
</mycat:rule>

```
在conf文件夹创建student_text.txt文件，内容如下  
![image.png](https://cdn.nlark.com/yuque/0/2021/png/12493186/1611822401734-1f6dc5b5-7662-4565-a189-06958b23e770.png#align=left&display=inline&height=176&margin=%5Bobject%20Object%5D&name=image.png&originHeight=176&originWidth=447&size=14714&status=done&style=none&width=447)

vim student_text.txt  
![](https://cdn.nlark.com/yuque/0/2021/png/12493186/1611822291324-1940f7b8-824c-443c-843e-aa1365cf05f3.png#align=left&display=inline&height=40&margin=%5Bobject%20Object%5D&originHeight=40&originWidth=320&size=0&status=done&style=none&width=320)

内容如下，需要注意的是  
0-1M ，为0<=id<=10000,  
1M-2M，为10000<id<=20000，因为只定义了两个范围。如果超过20000例如20001会报错  
说明一下：1k=1000 ， 1M=10000  
schema.xml中t_student的 table标签值对应了两个dataNode节点，所以此处只有两个规则，不能多，也不能少
<table name="t_student" dataNode="dn1,dn3" primaryKey="id" rule="student_id" />

## 三、启动
### 3.1  新建数据库
使用navicat分别在两台mysql服务上新建3个数据库,192.168.244.105新建db1和db2，192.168.244.106新建db3。与schema.xml的dataNode节点对应。
``` 
<dataNode name="dn1" dataHost="dtHost1" database="db1" />
<dataNode name="dn2" dataHost="dtHost1" database="db2" />
<dataNode name="dn3" dataHost="dtHost2" database="db3" />
```

### 3.2  启动Mycat
进入Mycat的bin目录，在bin文件夹下执行./mycat start命令即可启动。然后通过Navicat连接，注意端口为之前配置的8066，用户名和密码也是之前配置的roo和123456。然后在8066端口连接下执行sql语句:
``` 
DROP TABLE IF EXISTS `t_user`;
CREATE TABLE `t_user` (
  `id` int(11) NOT NULL,
  `name` varchar(255) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

DROP TABLE IF EXISTS `t_student`;
CREATE TABLE `t_student` (
  `id` int(11) NOT NULL,
  `s_name` varchar(255) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

DROP TABLE IF EXISTS `t_teacher`;
CREATE TABLE `t_teacher` (
  `id` int(11) NOT NULL,
  `t_name` varchar(255) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

DROP TABLE IF EXISTS `t_loginlog`;
CREATE TABLE `t_loginlog` (
  `id` int(11) NOT NULL,
  `user_id` int(11) NOT NULL,
  `create_time` date DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

DROP TABLE IF EXISTS `t_dictionaries`;
CREATE TABLE `t_dictionaries` (
  `id` int(11) NOT NULL,
  `name` varchar(255) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
```
执行结果如下，105和106数据库中的表是mycat根据schema创建的。
![image.png](https://cdn.nlark.com/yuque/0/2021/png/12493186/1611823378900-db55a246-c246-454a-8a61-717a0aa5f1d9.png#align=left&display=inline&height=542&margin=%5Bobject%20Object%5D&name=image.png&originHeight=542&originWidth=772&size=66003&status=done&style=none&width=772)

## 四、简单使用
### 4.1  全局表
一个真实的业务系统中，往往存在大量的类似字典表的表，这些表基本上很少变动，字典表具有以下几个特性：
• 变动不频繁；
• 数据量总体变化不大；
• 数据规模不大，很少有超过数十万条记录。
对于这类的表，在分片的情况下，当业务表因为规模而进行分片以后，业务表与这些附属的字典表之间的关联，就成了比较棘手的问题，所以 Mycat 中通过数据冗余来解决这类表的 join，即所有的分片都有一份数据的拷贝，所有将字典表或者符合字典表特性的一些表定义为全局表。  
数据冗余是解决跨分片数据 join 的一种很好的思路，也是数据切分规划的另外一条重要规则。  
t_dictionaries表为全局表，所以他的数据操作是同步在所有的数据节点上，上文可见db1、db2和db3中都有这张表，来插入一条数据试试。

插入数据
``` 
INSERT INTO `mydatabase`.`t_dictionaries`(`id`, `name`) VALUES (1, '1');
```
![image.png](https://cdn.nlark.com/yuque/0/2021/png/12493186/1611823670654-1d2803da-0f40-4f15-ac08-92d543c5a2f3.png#align=left&display=inline&height=224&margin=%5Bobject%20Object%5D&name=image.png&originHeight=224&originWidth=696&size=14500&status=done&style=none&width=696)  

观察db1、db2和db3      
![image.png](https://cdn.nlark.com/yuque/0/2021/png/12493186/1611823834138-6e65862f-9fac-4656-b1be-b3dc23139534.png#align=left&display=inline&height=112&margin=%5Bobject%20Object%5D&name=image.png&originHeight=126&originWidth=258&size=5393&status=done&style=none&width=229)![image.png](https://cdn.nlark.com/yuque/0/2021/png/12493186/1611823843503-d319548f-60b3-4d4e-a2e7-5fd7933aae50.png#align=left&display=inline&height=117&margin=%5Bobject%20Object%5D&name=image.png&originHeight=134&originWidth=256&size=5534&status=done&style=none&width=224)![image.png](https://cdn.nlark.com/yuque/0/2021/png/12493186/1611823853082-023eec06-0eea-451d-a50c-137c8ac671f2.png#align=left&display=inline&height=118&margin=%5Bobject%20Object%5D&name=image.png&originHeight=126&originWidth=244&size=5316&status=done&style=none&width=229)

可见他的数据操作是同步在所有的数据节点上的。

### 4.2  单节点表
t_teacher 并没有进行分片配置，也只定义了一个节点所以是单表，确认只有一个物理库中存在即可。  
插入数据：  
``` 
INSERT INTO `mydatabase`.`t_teacher`(`id`, `t_name`) VALUES (1, '小明');
```
观察db1  
![image.png](https://cdn.nlark.com/yuque/0/2021/png/12493186/1611824073590-6da77857-c24f-4c3d-8cdf-90c65ce07811.png#align=left&display=inline&height=119&margin=%5Bobject%20Object%5D&name=image.png&originHeight=119&originWidth=281&size=6219&status=done&style=none&width=281)

### 4.3  auto-sharding-long分片
schema.xml文件中t_user表使用了auto-sharding-long分片，我们可以在rule.xml文件 找到它使用的配置文件  
``` 
<function name="rang-long" class="io.mycat.route.function.AutoPartitionByLong">
    <property name="mapFile">autopartition-long.txt</property>
</function>
```
可知，它的配置文件是autopartition-long.txt， 我们在conf目录找它。    
![image.png](https://cdn.nlark.com/yuque/0/2021/png/12493186/1611824955876-6160f9a2-60b3-4706-a9bc-3d3dbaead69c.png#align=left&display=inline&height=456&margin=%5Bobject%20Object%5D&name=image.png&originHeight=456&originWidth=635&size=59664&status=done&style=none&width=635)  
![image.png](https://cdn.nlark.com/yuque/0/2021/png/12493186/1611824987865-a524707f-2c69-4edd-ac84-4364cbdfe679.png#align=left&display=inline&height=121&margin=%5Bobject%20Object%5D&name=image.png&originHeight=121&originWidth=363&size=6024&status=done&style=none&width=363)  
由此可推断，t_user表id为0-5000000之间存储在db1节点，5000001-10000000存储在db2节点，10000001-15000000存储在db3节点。边界值5000000这条记录会插入db1节点。  
插入数据  
``` 
INSERT INTO `mydatabase`.`t_user`(`id`, `name`) VALUES (1, '1');
INSERT INTO `mydatabase`.`t_user`(`id`, `name`) VALUES (4000000, '4000000');
INSERT INTO `mydatabase`.`t_user`(`id`, `name`) VALUES (5000001, '5000001');
INSERT INTO `mydatabase`.`t_user`(`id`, `name`) VALUES (9000000, '9000000');
INSERT INTO `mydatabase`.`t_user`(`id`, `name`) VALUES (10000001, '10000001');
INSERT INTO `mydatabase`.`t_user`(`id`, `name`) VALUES (14000000, '14000000');
```

![image.png](https://cdn.nlark.com/yuque/0/2021/png/12493186/1611825127314-2c5ac798-5618-4e4a-ab29-7416aaa348e1.png#align=left&display=inline&height=585&margin=%5Bobject%20Object%5D&name=image.png&originHeight=585&originWidth=649&size=46364&status=done&style=none&width=649)

观察db1、db2和db3，可见根据id插入了不同的库。  
![image.png](https://cdn.nlark.com/yuque/0/2021/png/12493186/1611825162307-d0135a34-fffc-42c4-b381-962d3634673b.png#align=left&display=inline&height=118&margin=%5Bobject%20Object%5D&name=image.png&originHeight=145&originWidth=287&size=6593&status=done&style=none&width=233)![image.png](https://cdn.nlark.com/yuque/0/2021/png/12493186/1611825327796-8414dbfe-7092-4283-a1f0-845cb7f9e568.png#align=left&display=inline&height=118&margin=%5Bobject%20Object%5D&name=image.png&originHeight=136&originWidth=268&size=6772&status=done&style=none&width=233)![image.png](https://cdn.nlark.com/yuque/0/2021/png/12493186/1611825204080-8b5dc6b2-75c2-4750-809e-6c60dcdeb748.png#align=left&display=inline&height=117&margin=%5Bobject%20Object%5D&name=image.png&originHeight=137&originWidth=291&size=6869&status=done&style=none&width=248)

autopartition-long.txt只定义id到15000000的范围，那么插入id为15000001的数据会发生什么呢？mycat会提示找不到节点。  
![image.png](https://cdn.nlark.com/yuque/0/2021/png/12493186/1611827155109-c3da453e-bbf1-4371-91ea-f9f56ca1dd1f.png#align=left&display=inline&height=198&margin=%5Bobject%20Object%5D&name=image.png&originHeight=198&originWidth=678&size=11120&status=done&style=none&width=678)

### 4.4  ER分片
关系型数据库是基于实体关系模型（Entity-Relationship Model)之上，通过其描述了真实世界中事物与关系，Mycat 中的 ER 表即是来源于此。  
根据这一思路，提出了基于 E-R 关系的数据分片策略，子表的记录与所关联的父表记录存放在同一个数据分片上，即子表依赖于父表，通过表分组（Table Group）保证数据 Join 不会跨库操作。  
schema.xml文件中t_loginlog表是根据t_user表的主外键规则进行分片    
``` 
<table name="t_user" dataNode="dn1,dn2,dn3" primaryKey="id" rule="auto-sharding-long">
    <childTable name="t_loginlog" primaryKey="id" joinKey="user_id" parentKey="id"></childTable>
</table>
```

插入数据（sql中未建立外键关系，所以可以直接插入数据）  
``` 
INSERT INTO `mydatabase`.`t_loginlog`(`id`, `user_id`, `create_time`) VALUES (1, 1, now());
INSERT INTO `mydatabase`.`t_loginlog`(`id`, `user_id`, `create_time`) VALUES (2, 5000001, now());
INSERT INTO `mydatabase`.`t_loginlog`(`id`, `user_id`, `create_time`) VALUES (3, 14000000, now());
```

![image.png](https://cdn.nlark.com/yuque/0/2021/png/12493186/1611826302159-e936ae3c-2373-40d9-8ba3-c07a49a3de93.png#align=left&display=inline&height=375&margin=%5Bobject%20Object%5D&name=image.png&originHeight=375&originWidth=804&size=31959&status=done&style=none&width=804)

观察db1、db2和db3，可见根据外键user_id插入了不同的库。  
![image.png](https://cdn.nlark.com/yuque/0/2021/png/12493186/1611826340889-092e7234-e074-4efa-898b-4f371f9bbe7b.png#align=left&display=inline&height=102&margin=%5Bobject%20Object%5D&name=image.png&originHeight=118&originWidth=270&size=6503&status=done&style=none&width=234)![image.png](https://cdn.nlark.com/yuque/0/2021/png/12493186/1611826355753-a914c39f-df49-4f78-95d3-0f7b3d6c243f.png#align=left&display=inline&height=99&margin=%5Bobject%20Object%5D&name=image.png&originHeight=114&originWidth=280&size=6789&status=done&style=none&width=244)![image.png](https://cdn.nlark.com/yuque/0/2021/png/12493186/1611826369923-e5ceb317-2df9-4cde-991b-97ad0b6f5d69.png#align=left&display=inline&height=102&margin=%5Bobject%20Object%5D&name=image.png&originHeight=126&originWidth=280&size=6918&status=done&style=none&width=227)

执行一次inner join的查询  
![image.png](https://cdn.nlark.com/yuque/0/2021/png/12493186/1611826867310-8138e9eb-359a-4571-b276-9a4df01f369c.png#align=left&display=inline&height=259&margin=%5Bobject%20Object%5D&name=image.png&originHeight=259&originWidth=602&size=12416&status=done&style=none&width=602)

执行一次left join的查询  
![image.png](https://cdn.nlark.com/yuque/0/2021/png/12493186/1611826882367-6caed4b5-47fb-4a45-86e4-b2a0fca5a354.png#align=left&display=inline&height=377&margin=%5Bobject%20Object%5D&name=image.png&originHeight=377&originWidth=635&size=21081&status=done&style=none&width=635)

### 4.5 自定义的mapFile分片
schema.xml配置中，t_student表配置了2个节点，分片规则是student_id. <table name="t_student" dataNode="dn1,dn3" primaryKey="id" rule="student_id" />
rule.xml配置中,student_id规则使用id列，算法为student_text。算法student_text使用了类AutoPartitionByLong和规则文件student_text.txt，我们在conf目录已经创建过了。
``` 
<tableRule name="student_id">
    <rule>
         <columns>id</columns>
         <algorithm>student_text</algorithm>
    </rule>
</tableRule>
<!--在conf中需要添加student_text.txt规则文件-->
<function name="student_text"class="io.mycat.route.function.AutoPartitionByLong">
     <property name="mapFile">student_text.txt</property>
</function>
```

![](https://cdn.nlark.com/yuque/0/2021/png/12493186/1611822401734-1f6dc5b5-7662-4565-a189-06958b23e770.png#align=left&display=inline&height=176&margin=%5Bobject%20Object%5D&originHeight=176&originWidth=447&status=done&style=none&width=447)

M=10000
这里可以看出 t_student表和t_user表的分片规则是一样的，只不过是使用了自定义的mapFile,作为分片规则文件。  
我们在Mycat端插入几条数据,执行以下sql:  
``` 
INSERT INTO `mydatabase`.`t_student`(`id`, `s_name`) VALUES (0, '00');
INSERT INTO `mydatabase`.`t_student`(`id`, `s_name`) VALUES (1, '111');
INSERT INTO `mydatabase`.`t_student`(`id`, `s_name`) VALUES (10000, '10000');
INSERT INTO `mydatabase`.`t_student`(`id`, `s_name`) VALUES (10001, '10001');
INSERT INTO `mydatabase`.`t_student`(`id`, `s_name`) VALUES (20000, '20000');
```

![image.png](https://cdn.nlark.com/yuque/0/2021/png/12493186/1611889227072-46d259a2-3159-4796-9b21-7831a59b5835.png#align=left&display=inline&height=507&margin=%5Bobject%20Object%5D&name=image.png&originHeight=507&originWidth=748&size=43340&status=done&style=none&width=748)

观察db1和db3的t_student表  
![image.png](https://cdn.nlark.com/yuque/0/2021/png/12493186/1611889261386-d3f8b942-75ac-4f08-a228-cf1e5b6f5970.png#align=left&display=inline&height=146&margin=%5Bobject%20Object%5D&name=image.png&originHeight=166&originWidth=284&size=7104&status=done&style=none&width=249)![image.png](https://cdn.nlark.com/yuque/0/2021/png/12493186/1611889269416-8407f3e7-52bb-4c88-8c0e-839c081939b7.png#align=left&display=inline&height=145&margin=%5Bobject%20Object%5D&name=image.png&originHeight=145&originWidth=298&size=7014&status=done&style=none&width=298)  

可见已经按照student_text.txt做了分表。  

## 五、简单总结
通过以上的安装、配合和测试的学习，应该可以初步实现分库分表的功能了。现在来简单看一下在第四节用到两次的分片函数AutoPartitionByLong类，Mycat源码可以在这里找到:[https://github.com/MyCATApache/Mycat-Server](https://github.com/MyCATApache/Mycat-Server)。
``` 
package io.mycat.route.function;

import java.io.BufferedReader;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.util.HashSet;
import java.util.LinkedList;
import java.util.Set;

import io.mycat.config.model.rule.RuleAlgorithm;

/**
 * auto partition by Long ,can be used in auto increment primary key partition
 * 
 * @author wuzhi
 */
public class AutoPartitionByLong extends AbstractPartitionAlgorithm implements RuleAlgorithm{

	private String mapFile;
	private LongRange[] longRongs;
	
	private int defaultNode = -1;
	@Override
	public void init() {

		initialize();
	}

	public void setMapFile(String mapFile) {
		this.mapFile = mapFile;
	}

	@Override
	public Integer calculate(String columnValue)  {
//		columnValue = NumberParseUtil.eliminateQoute(columnValue);
		try {
			long value = Long.parseLong(columnValue);
			Integer rst = null;
			for (LongRange longRang : this.longRongs) {
				if (value <= longRang.valueEnd && value >= longRang.valueStart) {
					return longRang.nodeIndx;
				}
			}
			//数据超过范围，暂时使用配置的默认节点
			if (rst == null && defaultNode >= 0) {
				return defaultNode;
			}
			return rst;
		} catch (NumberFormatException e){
			throw new IllegalArgumentException(new StringBuilder().append("columnValue:").append(columnValue).append(" Please eliminate any quote and non number within it.").toString(),e);
		}
	}
	
	@Override
	public Integer[] calculateRange(String beginValue, String endValue)  {
		return AbstractPartitionAlgorithm.calculateSequenceRange(this, beginValue, endValue);
	}

	@Override
	public int getPartitionNum() {
//		int nPartition = longRongs.length;
		
		/*
		 * fix #1284 这里的统计应该统计Range的nodeIndex的distinct总数
		 */
		Set<Integer> distNodeIdxSet = new HashSet<Integer>();
		for(LongRange range : longRongs) {
			distNodeIdxSet.add(range.nodeIndx);
		}
		int nPartition = distNodeIdxSet.size();
		return nPartition;
	}

	private void initialize() {
		BufferedReader in = null;
		try {
			// FileInputStream fin = new FileInputStream(new File(fileMapPath));
			InputStream fin = this.getClass().getClassLoader()
					.getResourceAsStream(mapFile);
			if (fin == null) {
				throw new RuntimeException("can't find class resource file "
						+ mapFile);
			}
			in = new BufferedReader(new InputStreamReader(fin));
			LinkedList<LongRange> longRangeList = new LinkedList<LongRange>();

			for (String line = null; (line = in.readLine()) != null;) {
				line = line.trim();
				if (line.startsWith("#") || line.startsWith("//")) {
					continue;
				}
				int ind = line.indexOf('=');
				if (ind < 0) {
					System.out.println(" warn: bad line int " + mapFile + " :"
							+ line);
					continue;
				}
					String pairs[] = line.substring(0, ind).trim().split("-");
					long longStart = NumberParseUtil.parseLong(pairs[0].trim());
					long longEnd = NumberParseUtil.parseLong(pairs[1].trim());
					int nodeId = Integer.parseInt(line.substring(ind + 1)
							.trim());
					longRangeList
							.add(new LongRange(nodeId, longStart, longEnd));

			}
			longRongs = longRangeList.toArray(new LongRange[longRangeList
					.size()]);
		} catch (Exception e) {
			if (e instanceof RuntimeException) {
				throw (RuntimeException) e;
			} else {
				throw new RuntimeException(e);
			}

		} finally {
			try {
				in.close();
			} catch (Exception e2) {
			}
		}
	}
	
	public int getDefaultNode() {
		return defaultNode;
	}

	public void setDefaultNode(int defaultNode) {
		this.defaultNode = defaultNode;
	}

	static class LongRange {
		public final int nodeIndx;
		public final long valueStart;
		public final long valueEnd;

		public LongRange(int nodeIndx, long valueStart, long valueEnd) {
			super();
			this.nodeIndx = nodeIndx;
			this.valueStart = valueStart;
			this.valueEnd = valueEnd;
		}

	}
}
```
AutoPartitionByLong主要属性和方法介绍:

- mapFile属性,存储的是 rule.xml中的标签<property name="mapFile">student_text.txt</property>中定义的文件名称;
- LongRange数组属性,存储的是文件中的边界值信息，包括nodeId节点id, longStart开始值, longEnd结束值;
- calculate(String columnValue) 方法，计算long值应该存在的节点id;
- initialize()方法,读取mapFile文件初始化LongRange数组。


当 Mycat 收到一个insert  SQL 时，会先解析这个 SQL，查找涉及到的表，然后看此表的定义，如果有分片规则，则获取到 SQL 里分片字段的值，并匹配分片函数，得到需要插入的节点，执行插入操作。

